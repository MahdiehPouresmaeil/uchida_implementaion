{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST98LX_z8uHh"
   },
   "source": [
    "# **Base model with embedding watermark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcbTIZqIF7zS"
   },
   "source": [
    "\n",
    "Epoch [1/10], Test Accuracy: 64.96%, Classification Loss: 1.7705, Watermark Loss: 0.0070\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [1. 1. 0. 0. 0. 1. 1. 0.]\n",
    "\n",
    "BER 0.75\n",
    "Epoch [2/10], Test Accuracy: 97.11%, Classification Loss: 1.5053, Watermark Loss: 0.0069\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 0. 0. 0. 1. 0.]\n",
    "\n",
    "BER 0.5\n",
    "Epoch [3/10], Test Accuracy: 97.67%, Classification Loss: 1.4900, Watermark Loss: 0.0068\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 0. 1. 0. 1. 0.]\n",
    "\n",
    "BER 0.375\n",
    "Epoch [4/10], Test Accuracy: 98.05%, Classification Loss: 1.4667, Watermark Loss: 0.0068\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 0. 1. 0. 1. 0.]\n",
    "\n",
    "BER 0.375\n",
    "Epoch [5/10], Test Accuracy: 98.00%, Classification Loss: 1.4613, Watermark Loss: 0.0067\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 0. 1. 0. 1. 0.]\n",
    "\n",
    "BER 0.375\n",
    "Epoch [6/10], Test Accuracy: 98.17%, Classification Loss: 1.4720, Watermark Loss: 0.0066\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 1. 1. 0. 1. 0.]\n",
    "\n",
    "BER 0.25\n",
    "Epoch [7/10], Test Accuracy: 98.36%, Classification Loss: 1.4615, Watermark Loss: 0.0066\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "BER 0.0\n",
    "✅ Model saved with Test Accuracy: 98.36% and BER: 0.0000 and bestepoch: 7\n",
    "Epoch [8/10], Test Accuracy: 98.38%, Classification Loss: 1.4703, Watermark Loss: 0.0065\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "BER 0.0\n",
    "✅ Model saved with Test Accuracy: 98.38% and BER: 0.0000 and bestepoch: 8\n",
    "Epoch [9/10], Test Accuracy: 98.46%, Classification Loss: 1.4671, Watermark Loss: 0.0064\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "BER 0.0\n",
    "✅ Model saved with Test Accuracy: 98.46% and BER: 0.0000 and bestepoch: 9\n",
    "Epoch [10/10], Test Accuracy: 98.42%, Classification Loss: 1.4612, Watermark Loss: 0.0064\n",
    "\n",
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "BER 0.0\n",
    "✅Final  Model Test Accuracy: 98.46% and BER: 0.0000 and bestepoch: 9\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:58:21.690285Z",
     "start_time": "2025-03-31T12:58:21.685074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ],
   "outputs": [],
   "execution_count": 308
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:58:22.983529Z",
     "start_time": "2025-03-31T12:58:22.976102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 58  # You can choose any number\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # If using multiple GPUs\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior\n",
    "torch.backends.cudnn.benchmark = False  # Disable benchmark for reproducibility\n"
   ],
   "outputs": [],
   "execution_count": 309
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:58:23.564841Z",
     "start_time": "2025-03-31T12:58:23.559032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 310
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:44:43.301801Z",
     "start_time": "2025-03-31T13:44:43.296911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Hyperparameters\n",
    "num_epochs =30\n",
    "batch_size = 256\n",
    "learning_rate =0.001\n",
    "lambda_wm =1e-1# 1e-2 Watermark regularizer 0.01\n",
    "best_acc = 0.0  # Track best test accuracy\n",
    "best_ber = float(\"inf\")  # Track lowest BER\n",
    "best_model_path = \"best_model.pth\"\n"
   ],
   "outputs": [],
   "execution_count": 341
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:58:25.201479Z",
     "start_time": "2025-03-31T12:58:25.099054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "\n",
    "\n",
    "# !rm -rf ./data/MNIST\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.RandomRotation(10),  # Rotate images by ±10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)  # Test set\n",
    "\n",
    "# Use the same seed for the DataLoader shuffle\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(seed), generator=g)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ],
   "outputs": [],
   "execution_count": 312
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:58:25.958752Z",
     "start_time": "2025-03-31T12:58:25.953821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Computes the Bit Error Rate (BER)\n",
    "def compute_ber(original_watermark, extracted_watermark):\n",
    "  diff = original_watermark - extracted_watermark\n",
    "  num_errors = torch.sum(torch.abs(diff))\n",
    "  ber = num_errors.float() / original_watermark.numel()\n",
    "  return ber.item() #float\n"
   ],
   "outputs": [],
   "execution_count": 313
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:58:27.704199Z",
     "start_time": "2025-03-31T12:58:27.697046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define Watermark Regularizer\n",
    "class WatermarkRegularizer(nn.Module):\n",
    "    def __init__(self, lambda_wm, watermark_vector, C_in, K):\n",
    "        super(WatermarkRegularizer, self).__init__()\n",
    "        self.lambda_wm = lambda_wm  # Watermark regularizer\n",
    "        self.watermark_vector = watermark_vector  #  watermark vector\n",
    "        T=watermark_vector.shape[0]\n",
    "        M = C_in*K*K  # Hidden dimension for projection\n",
    "        self.secret_key = torch.randn(T, M, device=device)\n",
    "        # self.secret_key = torch.nn.functional.normalize(self.secret_key, p=2, dim=1)\n",
    "        # print(self.secret_key.shape)   #8,9\n",
    "\n",
    "    def forward(self, weights, criterion):\n",
    "        # print(weights.size())   #32,1,3,3\n",
    "        w_mean = weights.mean(dim=(0))  # mean of filters\n",
    "        # print(w_mean.size())   #1*3*3\n",
    "        w_mean_flat = w_mean.view(-1)  # Flatten(C_in * K * K)\n",
    "        # print(w_mean_flat.size())   #9\n",
    "        # print(self.secret_key.T.size())  #9,8\n",
    "        projected_wm = torch.sigmoid(torch.matmul (self.secret_key,w_mean_flat))  # Compute WX\n",
    "        # wm_loss=self.lambda_wm * torch.norm(projected_wm - self.watermark_vector)  # Regularization loss\n",
    "        wm_loss =  criterion(projected_wm.to(device), self.watermark_vector.to(device))\n",
    "        # wm_loss = self.lambda_wm * nn.BCELoss(reduction='mean')(projected_wm.to(device), self.watermark_vector.to(device))\n",
    "        # print((projected_wm > 0.5).float())\n",
    "        # print(self.watermark_vector)\n",
    "        # print('***************************************')\n",
    "\n",
    "        return wm_loss"
   ],
   "outputs": [],
   "execution_count": 314
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:27:07.163292Z",
     "start_time": "2025-03-31T13:27:07.155755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a Simple CNN with Watermark Embedding\n",
    "class WatermarkedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WatermarkedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 28 *28, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        # self.wm_regularizer = WatermarkRegularizer(lambda_wm, watermark_vector, C_in=1, K=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x)) # watermark is here\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # x=torch.sigmoid(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 325
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:14:00.271877Z",
     "start_time": "2025-03-31T14:14:00.240064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# generate a random watermark, ignoring the seed\n",
    "# rand_gen = torch.Generator(device)  # Create a new generator\n",
    "# rand_gen.seed()  # Seed it randomly\n",
    "\n",
    "# # Generate a new random watermark vector using this independent generator\n",
    "# watermark_vector = torch.randint(0, 2, (256,), dtype=torch.float32, device=device, generator=rand_gen)\n",
    "\n",
    "\n",
    "watermark_vector = torch.randint(0, 2, (256,), dtype=torch.float32, device=device)  # Binary watermark\n",
    "print(watermark_vector)\n",
    "\n",
    "\n",
    "# watermark_vector=torch.tensor([0., 1., 0., 1., 1., 0., 0., 1.], dtype=torch.float32)\n",
    "\n",
    "# print(watermark_vector)\n",
    "# print(watermark_vector.size()) #8"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 416
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "NocXpnQb4Ych",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "adf0de91-755b-43f0-f206-ea10d867569f",
    "ExecuteTime": {
     "end_time": "2025-03-31T14:21:21.632132Z",
     "start_time": "2025-03-31T14:14:08.099925Z"
    }
   },
   "source": [
    "\n",
    "#BASE_EMBEDDED_MODEL\n",
    "\n",
    "model = WatermarkedCNN().to(device)\n",
    "criterion2=nn.BCELoss()\n",
    "wm_regularizer = WatermarkRegularizer(lambda_wm, watermark_vector, C_in=32, K=3)\n",
    "torch.save(wm_regularizer.secret_key, \"secret_key.pth\")  # Save the secret key\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss_class = criterion(outputs, labels)\n",
    "        wm_loss = wm_regularizer(model.conv2.weight, criterion2)\n",
    "        loss = loss_class + (lambda_wm * wm_loss)  # Total loss\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # current_lr = optimizer.param_groups[0]['lr']\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Learning Rate: {current_lr:.6f}\")\n",
    "    # scheduler.step()\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "          for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class index with highest probability\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "    accuracy = 100 * correct / total  # Compute accuracy percentage\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%, Classification Loss: {loss_class.item():.4f}, \"\n",
    "          f\"Watermark Loss: {wm_loss.item():.4f}\")\n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}],  Classification Loss: {loss_class.item():.4f}, \"\n",
    "    #       f\"Watermark Loss: {wm_loss.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "      conv2_mean = model.conv2.weight.mean(dim=0)  # Should be (1,3,3)\n",
    "      conv2_mean_flat = conv2_mean.view(-1)\n",
    "      extracted_watermark = torch.sigmoid(torch.matmul( wm_regularizer.secret_key.cpu(), conv2_mean_flat.cpu()))  # Fix dimensions\n",
    "      extracted_watermark_binary = (extracted_watermark > 0.5).float()\n",
    "      # print(type(extracted_watermark_binary))\n",
    "      # print(type(watermark_vector))\n",
    "      # print(\"\\nOriginal Watermark:\", watermark_vector.cpu().numpy())\n",
    "      # print(\"\\nExtracted Watermark:\", extracted_watermark_binary.cpu().numpy())\n",
    "      print(\"\\nBER\", compute_ber(watermark_vector.cpu(), extracted_watermark_binary.cpu()))\n",
    "\n",
    "    ber=compute_ber(watermark_vector.cpu(), extracted_watermark_binary.cpu())\n",
    "    if accuracy>best_acc and ber<=0.0:\n",
    "        if os.path.exists(best_model_path):\n",
    "          os.remove(best_model_path)\n",
    "        best_acc=accuracy\n",
    "        best_ber=ber\n",
    "        best_epoch=epoch+1\n",
    "        best_model_path = f\"best_model_lR:{learning_rate}_lamda:{lambda_wm}_Acc:{best_acc}_Epoch:{best_epoch}_Ber:{best_ber}.pth\"\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Model saved with Test Accuracy: {best_acc:.2f}% and BER: {best_ber:.4f} and bestepoch: {best_epoch}\")\n",
    "\n",
    "print(f\"✅Final  Model Test Accuracy: {best_acc:.2f}% and BER: {best_ber:.4f} and bestepoch: {best_epoch}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Test Accuracy: 97.10%, Classification Loss: 1.4724, Watermark Loss: 0.5175\n",
      "\n",
      "BER 0.1796875\n",
      "Epoch [2/30], Test Accuracy: 97.85%, Classification Loss: 1.4827, Watermark Loss: 0.4163\n",
      "\n",
      "BER 0.12890625\n",
      "Epoch [3/30], Test Accuracy: 98.38%, Classification Loss: 1.4678, Watermark Loss: 0.3492\n",
      "\n",
      "BER 0.07421875\n",
      "Epoch [4/30], Test Accuracy: 98.39%, Classification Loss: 1.4618, Watermark Loss: 0.2990\n",
      "\n",
      "BER 0.046875\n",
      "Epoch [5/30], Test Accuracy: 98.56%, Classification Loss: 1.4629, Watermark Loss: 0.2593\n",
      "\n",
      "BER 0.03125\n",
      "Epoch [6/30], Test Accuracy: 98.44%, Classification Loss: 1.4719, Watermark Loss: 0.2275\n",
      "\n",
      "BER 0.01953125\n",
      "Epoch [7/30], Test Accuracy: 98.46%, Classification Loss: 1.4832, Watermark Loss: 0.2015\n",
      "\n",
      "BER 0.01171875\n",
      "Epoch [8/30], Test Accuracy: 98.42%, Classification Loss: 1.4720, Watermark Loss: 0.1797\n",
      "\n",
      "BER 0.00390625\n",
      "Epoch [9/30], Test Accuracy: 98.52%, Classification Loss: 1.4612, Watermark Loss: 0.1608\n",
      "\n",
      "BER 0.0\n",
      "Epoch [10/30], Test Accuracy: 98.73%, Classification Loss: 1.4612, Watermark Loss: 0.1449\n",
      "\n",
      "BER 0.0\n",
      "Epoch [11/30], Test Accuracy: 98.73%, Classification Loss: 1.4613, Watermark Loss: 0.1311\n",
      "\n",
      "BER 0.0\n",
      "Epoch [12/30], Test Accuracy: 98.74%, Classification Loss: 1.4612, Watermark Loss: 0.1191\n",
      "\n",
      "BER 0.0\n",
      "Epoch [13/30], Test Accuracy: 98.59%, Classification Loss: 1.4612, Watermark Loss: 0.1086\n",
      "\n",
      "BER 0.0\n",
      "Epoch [14/30], Test Accuracy: 98.21%, Classification Loss: 1.4716, Watermark Loss: 0.0994\n",
      "\n",
      "BER 0.0\n",
      "Epoch [15/30], Test Accuracy: 98.49%, Classification Loss: 1.4612, Watermark Loss: 0.0914\n",
      "\n",
      "BER 0.0\n",
      "Epoch [16/30], Test Accuracy: 98.62%, Classification Loss: 1.4612, Watermark Loss: 0.0841\n",
      "\n",
      "BER 0.0\n",
      "Epoch [17/30], Test Accuracy: 98.53%, Classification Loss: 1.4716, Watermark Loss: 0.0775\n",
      "\n",
      "BER 0.0\n",
      "Epoch [18/30], Test Accuracy: 98.73%, Classification Loss: 1.4612, Watermark Loss: 0.0717\n",
      "\n",
      "BER 0.0\n",
      "Epoch [19/30], Test Accuracy: 98.65%, Classification Loss: 1.4612, Watermark Loss: 0.0664\n",
      "\n",
      "BER 0.0\n",
      "Epoch [20/30], Test Accuracy: 98.53%, Classification Loss: 1.4621, Watermark Loss: 0.0620\n",
      "\n",
      "BER 0.0\n",
      "Epoch [21/30], Test Accuracy: 98.73%, Classification Loss: 1.4922, Watermark Loss: 0.0578\n",
      "\n",
      "BER 0.0\n",
      "Epoch [22/30], Test Accuracy: 98.50%, Classification Loss: 1.4820, Watermark Loss: 0.0543\n",
      "\n",
      "BER 0.0\n",
      "Epoch [23/30], Test Accuracy: 98.60%, Classification Loss: 1.4612, Watermark Loss: 0.0510\n",
      "\n",
      "BER 0.0\n",
      "Epoch [24/30], Test Accuracy: 98.67%, Classification Loss: 1.4716, Watermark Loss: 0.0479\n",
      "\n",
      "BER 0.0\n",
      "Epoch [25/30], Test Accuracy: 98.64%, Classification Loss: 1.4612, Watermark Loss: 0.0452\n",
      "\n",
      "BER 0.0\n",
      "Epoch [26/30], Test Accuracy: 98.55%, Classification Loss: 1.4612, Watermark Loss: 0.0429\n",
      "\n",
      "BER 0.0\n",
      "Epoch [27/30], Test Accuracy: 98.64%, Classification Loss: 1.4612, Watermark Loss: 0.0406\n",
      "\n",
      "BER 0.0\n",
      "Epoch [28/30], Test Accuracy: 98.91%, Classification Loss: 1.4612, Watermark Loss: 0.0385\n",
      "\n",
      "BER 0.0\n",
      "✅ Model saved with Test Accuracy: 98.91% and BER: 0.0000 and bestepoch: 28\n",
      "Epoch [29/30], Test Accuracy: 98.71%, Classification Loss: 1.4820, Watermark Loss: 0.0366\n",
      "\n",
      "BER 0.0\n",
      "Epoch [30/30], Test Accuracy: 98.79%, Classification Loss: 1.4612, Watermark Loss: 0.0348\n",
      "\n",
      "BER 0.0\n",
      "✅Final  Model Test Accuracy: 98.91% and BER: 0.0000 and bestepoch: 28\n"
     ]
    }
   ],
   "execution_count": 417
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "874PmbC4CRbq"
   },
   "source": [
    "# **Base model without watermark**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "EbKW3MdVCRLG",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "67e12ebe-2b4d-4676-c8b0-051b7b158c67",
    "ExecuteTime": {
     "end_time": "2025-03-28T14:25:45.813804Z",
     "start_time": "2025-03-28T14:23:20.779860Z"
    }
   },
   "source": [
    "#BASE_MODEL_NOT_EMBEDED\n",
    "# # generate a random watermark, ignoring the seed\n",
    "# rand_gen = torch.Generator(device)  # Create a new generator\n",
    "# rand_gen.seed()  # Seed it randomly\n",
    "best_model_path = \"best_model2.pth\"\n",
    "\n",
    "\n",
    "model = WatermarkedCNN().to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss_class = criterion(outputs, labels)\n",
    "        loss = loss_class  # Total loss\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "          for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class index with highest probability\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "    accuracy = 100 * correct / total  # Compute accuracy percentage\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%, Classification Loss: {loss_class.item():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    if accuracy>best_acc :\n",
    "        if os.path.exists(best_model_path):\n",
    "          os.remove(best_model_path)\n",
    "        best_acc=accuracy\n",
    "        best_epoch=epoch+1\n",
    "        best_model_path = f\"best_model_lR:{learning_rate}_Acc:{best_acc}_Epoch:{best_epoch}.pth\"\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Model saved with Test Accuracy: {best_acc:.2f}%  and bestepoch: {best_epoch}\")\n",
    "\n",
    "\n",
    "print(f\"✅Final  Model Test Accuracy: {best_acc:.2f}% and bestepoch: {best_epoch}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Test Accuracy: 86.19%, Classification Loss: 1.5423\n",
      "Epoch [2/10], Test Accuracy: 87.02%, Classification Loss: 1.5721\n",
      "Epoch [3/10], Test Accuracy: 88.05%, Classification Loss: 1.5643\n",
      "Epoch [4/10], Test Accuracy: 97.81%, Classification Loss: 1.4625\n",
      "Epoch [5/10], Test Accuracy: 97.85%, Classification Loss: 1.4852\n",
      "Epoch [6/10], Test Accuracy: 98.49%, Classification Loss: 1.4727\n",
      "✅ Model saved with Test Accuracy: 98.49%  and bestepoch: 6\n",
      "Epoch [7/10], Test Accuracy: 98.46%, Classification Loss: 1.4615\n",
      "Epoch [8/10], Test Accuracy: 98.21%, Classification Loss: 1.4623\n",
      "Epoch [9/10], Test Accuracy: 98.52%, Classification Loss: 1.4716\n",
      "✅ Model saved with Test Accuracy: 98.52%  and bestepoch: 9\n",
      "Epoch [10/10], Test Accuracy: 98.19%, Classification Loss: 1.4877\n",
      "✅Final  Model Test Accuracy: 98.52% and bestepoch: 9\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TygIUrqq8j64"
   },
   "source": [
    "# **base:embeded model fine tuning without embeding- fine tune all parametres**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQcmQHwyGgMy"
   },
   "source": [
    "Original Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "Extracted Watermark: [0. 1. 0. 1. 1. 0. 0. 1.]\n",
    "\n",
    "BER 0.0"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VTrqJljt5LXn",
    "ExecuteTime": {
     "end_time": "2025-03-31T14:24:12.565090Z",
     "start_time": "2025-03-31T14:24:12.364897Z"
    }
   },
   "source": [
    "#fine tunning with the dataSET to see watermark still exist or not\n",
    "rand_gen = torch.Generator(device)  # Create a new generator\n",
    "rand_gen.seed()  # Seed it randomly\n",
    "# Assuming you have saved your model as 'model.pth'\n",
    "LR=0.0001\n",
    "model_finetune = WatermarkedCNN().to(device)  # Assuming WatermarkedCNN is your model class\n",
    "model_finetune.load_state_dict(torch.load('EMBEDED_256_RANDOM_model_lR:0.001_lamda:0.1_Acc:98.91_Epoch:28_Ber:0.0.pth'))\n",
    "# model_finetune.fc2 = nn.Linear(512, 10).to(device)\n",
    "model_finetune.eval()\n",
    "\n",
    "\n",
    "# for name, param in model_finetune.named_parameters():\n",
    "#     print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "optimizer = optim.Adam(model_finetune.parameters(), lr=LR)  #fine tune all parameteres\n",
    "# optimizer = optim.Adam(model_finetune.fc2.parameters(), lr=1e-3) #finetune just last layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "      conv2_mean = model_finetune.conv2.weight.mean(dim=0)  # Should be (1,3,3)\n",
    "      print(conv2_mean.size())\n",
    "      conv2_mean_flat = conv2_mean.view(-1)\n",
    "      extracted_watermark = torch.sigmoid(torch.matmul( wm_regularizer.secret_key.cpu(), conv2_mean_flat.cpu()))  # Fix dimensions\n",
    "      extracted_watermark_binary = (extracted_watermark > 0.5).float()\n",
    "\n",
    "      # print(type(extracted_watermark_binary))\n",
    "      # print(type(watermark_vector))\n",
    "\n",
    "      # print(\"\\nOriginal Watermark:\", watermark_vector.cpu().numpy())\n",
    "      # print(\"\\nExtracted Watermark:\", extracted_watermark_binary.cpu().numpy())\n",
    "      print(\"\\nBER\", compute_ber(watermark_vector.cpu(), extracted_watermark_binary.cpu()))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3])\n",
      "\n",
      "BER 0.0\n"
     ]
    }
   ],
   "execution_count": 419
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMq-ny7b72aZ",
    "outputId": "3fd532ee-d54b-4f33-b5fc-673761978f6a",
    "ExecuteTime": {
     "end_time": "2025-03-31T14:26:39.213832Z",
     "start_time": "2025-03-31T14:24:16.429212Z"
    }
   },
   "source": [
    "\n",
    "num_finetune_epochs = 10  # Adjust as needed\n",
    "best_finetune_acc = 0.0  # Track best test accuracy\n",
    "best_model_path = \"best_model_finetune.pth\"\n",
    "for epoch in range(num_finetune_epochs):\n",
    "    model_finetune.train()  # Ensure model is in training mode\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_finetune(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()\n",
    "\n",
    "        # for name, param in model_finetune.named_parameters():\n",
    "        #   if param.requires_grad and param.grad is not None:\n",
    "        #       print(f\"{name} - Grad Norm: {param.grad.norm().item()}\")\n",
    "        #\n",
    "        #\n",
    "        # for name, param in model_finetune.named_parameters():\n",
    "        #    if param.requires_grad:\n",
    "        #       print(f\"{name} - Grad After Backward: {param.grad}\")\n",
    "\n",
    "        # for param_group in optimizer.param_groups:\n",
    "        #     print(param_group['lr'])\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "    model_finetune.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "          for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs =model_finetune(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class index with highest probability\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "    accuracy = 100 * correct / total  # Compute accuracy percentage\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_finetune_epochs}], Test Accuracy: {accuracy:.2f}%, Classification Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    if accuracy>best_finetune_acc :\n",
    "        if os.path.exists(best_model_path):\n",
    "          os.remove(best_model_path)\n",
    "        best_finetune_acc =accuracy\n",
    "        best_epoch=epoch+1\n",
    "        best_model_path = f\"best_finetuned_model_lR:{LR}_Acc:{best_finetune_acc}_Epoch:{best_epoch}.pth\"\n",
    "        torch.save(model_finetune.state_dict(), best_model_path)\n",
    "        print(f\"✅ Model saved with Test Accuracy: {best_finetune_acc:.2f}% and bestepoch: {best_epoch}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Test Accuracy: 99.06%, Classification Loss: 1.4645\n",
      "✅ Model saved with Test Accuracy: 99.06% and bestepoch: 1\n",
      "Epoch [2/10], Test Accuracy: 98.99%, Classification Loss: 1.4612\n",
      "Epoch [3/10], Test Accuracy: 98.99%, Classification Loss: 1.4612\n",
      "Epoch [4/10], Test Accuracy: 98.99%, Classification Loss: 1.4612\n",
      "Epoch [5/10], Test Accuracy: 99.02%, Classification Loss: 1.4612\n",
      "Epoch [6/10], Test Accuracy: 99.01%, Classification Loss: 1.4716\n",
      "Epoch [7/10], Test Accuracy: 99.03%, Classification Loss: 1.4612\n",
      "Epoch [8/10], Test Accuracy: 99.04%, Classification Loss: 1.4612\n",
      "Epoch [9/10], Test Accuracy: 99.04%, Classification Loss: 1.4612\n",
      "Epoch [10/10], Test Accuracy: 99.01%, Classification Loss: 1.4612\n"
     ]
    }
   ],
   "execution_count": 420
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "collapsed": true,
    "id": "ZGgrhEnK937q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c6931eed-5980-49ac-ca9d-909a9e42bc04",
    "ExecuteTime": {
     "end_time": "2025-03-31T14:27:43.536752Z",
     "start_time": "2025-03-31T14:27:43.513129Z"
    }
   },
   "source": [
    "import copy\n",
    "# model_finetune2 = WatermarkedCNN().to(device)  # Assuming WatermarkedCNN is your model class\n",
    "\n",
    "# model_finetune2.load_state_dict(torch.load('0best_finetuned_model_lR:0.0001_Acc:98.67_Epoch:8.pth'))\n",
    "model_finetune2=copy.deepcopy(model_finetune)\n",
    "\n",
    "with torch.no_grad():\n",
    "      conv2_mean = model_finetune2.conv2.weight.mean(dim=0)  # Should be (1,3,3)\n",
    "      conv2_mean_flat = conv2_mean.view(-1)\n",
    "      extracted_watermark = torch.sigmoid(torch.matmul( wm_regularizer.secret_key.cpu(), conv2_mean_flat.cpu()))  # Fix dimensions\n",
    "      extracted_watermark_binary = (extracted_watermark > 0.5).float()\n",
    "\n",
    "      # print(type(extracted_watermark_binary))\n",
    "      # print(type(watermark_vector))\n",
    "\n",
    "      # print(\"\\nOriginal Watermark:\", watermark_vector.cpu().numpy())\n",
    "      # print(\"\\nExtracted Watermark:\", extracted_watermark_binary.cpu().numpy())\n",
    "      print(\"\\nBER\", compute_ber(watermark_vector.cpu(), extracted_watermark_binary.cpu()))\n",
    "\n",
    "#finish FINE_TUNING"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BER 0.0\n"
     ]
    }
   ],
   "execution_count": 421
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VVNnuZRHmeD"
   },
   "source": [
    "#**base:NOT embeded model fine tuning without embeding**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XKLfYOZCHoKS",
    "ExecuteTime": {
     "end_time": "2025-03-31T14:32:36.967Z",
     "start_time": "2025-03-31T14:32:36.753799Z"
    }
   },
   "source": [
    "#pruning the weights of the model\n",
    "\n",
    "\n",
    "rand_gen = torch.Generator(device)  # Create a new generator\n",
    "rand_gen.seed()  # Seed it randomly\n",
    "\n",
    "LR=0.0001\n",
    "model_prun= WatermarkedCNN().to(device)  # Assuming WatermarkedCNN is your model class\n",
    "model_prun.load_state_dict(torch.load('EMBEDED_256_RANDOM_model_lR:0.001_lamda:0.1_Acc:98.91_Epoch:28_Ber:0.0.pth'))\n",
    "# model_prun.eval()\n",
    "\n",
    "optimizer = optim.Adam(model_prun.parameters(), lr=LR)  #fine tune all parameteres\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model_finetune.fc2.parameters(), lr=1e-3) #finetune just last layer\n"
   ],
   "outputs": [],
   "execution_count": 475
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:32:37.430408Z",
     "start_time": "2025-03-31T14:32:37.423802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "model_copy=copy.deepcopy(model_prun)"
   ],
   "outputs": [],
   "execution_count": 476
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:32:38.924205Z",
     "start_time": "2025-03-31T14:32:38.845153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_dict1 = model_prun.state_dict()\n",
    "print(state_dict1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'conv1.weight': tensor([[[[ 3.0413e-01,  4.3302e-01, -1.8403e-01],\n",
      "          [-1.2042e-01,  1.7566e-01, -1.2720e-01],\n",
      "          [ 6.7383e-02, -5.6993e-02, -1.9650e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2970e-01,  1.3909e-01,  2.8890e-01],\n",
      "          [ 2.4254e-01, -1.5755e-01, -3.7578e-01],\n",
      "          [-2.3799e-01, -3.4658e-01, -2.1368e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6333e-01,  1.1173e-01,  2.1912e-01],\n",
      "          [-1.0194e-01,  1.2858e-01,  3.6664e-01],\n",
      "          [-4.3104e-01, -4.1460e-01,  3.6451e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1791e-01,  2.0427e-01, -4.3437e-01],\n",
      "          [ 8.8799e-02,  2.7934e-01, -4.0074e-01],\n",
      "          [ 1.0964e-01,  2.7541e-01,  9.8159e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9522e-02, -1.8267e-01, -4.1591e-01],\n",
      "          [ 1.5676e-01,  1.1256e-01, -2.4714e-01],\n",
      "          [ 1.7886e-01,  1.5345e-01, -2.4612e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1463e-01, -2.9220e-01,  2.2014e-01],\n",
      "          [ 1.8528e-01, -1.4020e-01, -7.7190e-02],\n",
      "          [-3.4701e-01, -2.4706e-01,  1.6660e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4254e-02,  1.9011e-01, -2.6717e-01],\n",
      "          [ 2.0139e-01, -4.1792e-01,  4.0164e-02],\n",
      "          [ 1.7847e-01, -2.9487e-01,  1.5483e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1981e-01,  2.1635e-02,  2.3061e-01],\n",
      "          [ 3.1149e-01,  3.3943e-01,  8.3049e-02],\n",
      "          [ 1.3916e-01,  2.0720e-01,  1.8383e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1669e-01,  1.1600e-01, -5.8576e-03],\n",
      "          [-2.0938e-01,  5.8822e-02,  1.6215e-01],\n",
      "          [ 2.1551e-01, -2.5478e-01,  9.0421e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5558e-01,  3.2284e-02,  2.6801e-01],\n",
      "          [ 3.3750e-01, -2.0981e-01, -2.3450e-01],\n",
      "          [ 2.7132e-01, -3.3797e-01, -2.6004e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0984e-01, -2.6576e-01, -3.6710e-01],\n",
      "          [-2.4983e-01, -4.8270e-02,  2.1199e-01],\n",
      "          [ 3.1303e-01, -8.7557e-02,  2.7878e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0007e-01, -1.5546e-01, -3.7219e-02],\n",
      "          [-3.1283e-01, -4.4517e-04,  2.8669e-01],\n",
      "          [-2.3850e-01,  3.0528e-01,  2.6590e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8433e-01, -8.4193e-02, -2.5090e-01],\n",
      "          [ 6.1337e-02, -2.6014e-01,  1.2028e-01],\n",
      "          [-2.7007e-01, -1.4069e-02,  2.8598e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1472e-01, -4.2987e-01, -3.7538e-01],\n",
      "          [ 3.8284e-01,  1.4180e-01, -3.7738e-02],\n",
      "          [ 1.3726e-01,  2.1754e-01,  5.4223e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0581e-01, -4.9804e-01,  2.1615e-01],\n",
      "          [-8.7263e-02, -1.7762e-01,  4.2348e-01],\n",
      "          [-3.7641e-01,  7.1862e-02,  1.4430e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.4154e-02, -7.7136e-02,  5.3799e-03],\n",
      "          [-1.5320e-01, -1.2278e-01, -2.2586e-01],\n",
      "          [-2.1018e-01,  2.8125e-01,  6.1945e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.0520e-01,  1.5813e-02, -1.9240e-01],\n",
      "          [-1.6061e-03,  1.2149e-01, -1.2648e-01],\n",
      "          [ 5.7403e-02,  1.8121e-02, -1.0134e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1848e-02, -2.1261e-01,  1.2779e-01],\n",
      "          [-2.7655e-01,  2.6501e-01,  2.4895e-01],\n",
      "          [-1.2696e-01,  2.4882e-01, -3.4592e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4517e-02,  3.5031e-01,  3.1131e-01],\n",
      "          [-4.1665e-01, -2.8873e-01,  1.0442e-01],\n",
      "          [-1.6583e-01,  3.0569e-01, -1.3651e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6648e-01, -1.0181e-01, -4.7248e-01],\n",
      "          [-2.0916e-01, -3.3438e-01,  1.6765e-01],\n",
      "          [ 1.3090e-01,  1.2699e-01,  9.5634e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.1274e-02, -1.0927e-01,  6.1549e-02],\n",
      "          [-3.9321e-02,  1.9125e-01, -3.1438e-01],\n",
      "          [-2.8286e-01,  3.3209e-01, -1.7902e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5108e-01,  1.2991e-01,  2.0874e-01],\n",
      "          [-3.8286e-01, -2.6219e-01,  1.1090e-01],\n",
      "          [-6.6871e-02, -1.8596e-01, -3.1794e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5592e-01,  2.9774e-01,  1.6309e-01],\n",
      "          [-1.1502e-01, -1.0641e-01, -1.4265e-01],\n",
      "          [-2.7828e-01, -2.9805e-01,  1.4115e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5709e-01, -2.0413e-02, -4.6657e-01],\n",
      "          [-1.8110e-01,  2.7570e-01, -1.9795e-01],\n",
      "          [-2.2737e-01,  2.8542e-01,  3.0082e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3938e-01, -3.6358e-01, -5.3598e-02],\n",
      "          [-6.2481e-02, -1.2456e-01,  2.6479e-01],\n",
      "          [ 2.9214e-01, -2.8463e-02,  2.6817e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6188e-01, -3.4488e-01,  9.5594e-02],\n",
      "          [-1.8720e-01,  1.4773e-01,  9.8693e-02],\n",
      "          [ 1.9680e-01,  2.8820e-01, -1.4721e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2094e-02, -6.9042e-02, -2.9274e-02],\n",
      "          [ 3.5994e-01,  1.7629e-01, -3.6647e-01],\n",
      "          [-3.9064e-01, -1.6649e-01,  4.0233e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2986e-01, -2.5649e-01,  2.5322e-01],\n",
      "          [-2.4171e-02, -4.4925e-02, -2.6643e-01],\n",
      "          [ 3.0556e-02,  1.6163e-01, -1.6492e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7636e-01,  1.2626e-01,  3.2265e-01],\n",
      "          [ 2.0514e-01,  1.6370e-01, -7.8297e-03],\n",
      "          [-2.3514e-01, -3.7728e-01, -3.8625e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2026e-02, -2.5059e-01,  3.7204e-02],\n",
      "          [-1.9873e-01, -1.8684e-01,  4.0724e-01],\n",
      "          [-2.9226e-01, -2.8523e-01,  3.2802e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3766e-01,  1.5075e-01,  9.4727e-02],\n",
      "          [ 3.8180e-01,  3.7533e-01,  1.7720e-01],\n",
      "          [-1.4431e-01,  3.3530e-02, -4.6331e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0900e-01, -3.2067e-01,  1.6041e-01],\n",
      "          [-1.4732e-01, -2.7287e-01, -3.7917e-01],\n",
      "          [-3.6473e-01,  4.8611e-02, -1.3377e-01]]]], device='cuda:0'), 'conv1.bias': tensor([-0.0712,  0.2060, -0.2511, -0.1535,  0.0375, -0.0435,  0.1309, -0.1793,\n",
      "         0.0359, -0.1097, -0.0226, -0.0414, -0.3093, -0.0661, -0.2690, -0.3514,\n",
      "         0.0366, -0.0638, -0.1240,  0.0477,  0.0278,  0.0976,  0.2227, -0.1390,\n",
      "         0.0254,  0.2546, -0.0774,  0.0057, -0.2141, -0.1512, -0.1839, -0.1054],\n",
      "       device='cuda:0'), 'conv2.weight': tensor([[[[-8.9108e-03, -2.3986e-01,  2.5394e-01],\n",
      "          [ 2.0963e-01,  1.0155e-01, -1.9567e-01],\n",
      "          [ 3.0319e-02,  3.9939e-02, -1.7175e-01]],\n",
      "\n",
      "         [[ 9.0353e-02, -1.2196e-01, -1.5819e-01],\n",
      "          [ 1.9754e-01, -1.6897e-02, -2.3974e-01],\n",
      "          [-2.1843e-01, -1.2314e-01, -1.2947e-01]],\n",
      "\n",
      "         [[-1.7323e-01, -1.7456e-01, -8.4748e-02],\n",
      "          [-7.1420e-02,  1.1860e-01, -2.5320e-02],\n",
      "          [ 1.8962e-01, -1.4106e-01, -7.5248e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3654e-01,  4.1491e-01, -5.5369e-01],\n",
      "          [-1.1298e-01,  4.6818e-02,  8.5527e-01],\n",
      "          [-2.7313e-01, -6.2151e-01,  4.8367e-02]],\n",
      "\n",
      "         [[ 4.1242e-01, -1.9455e-01, -3.8205e-01],\n",
      "          [-1.6556e-01, -5.0334e-02,  3.3277e-01],\n",
      "          [-3.3255e-02, -1.7340e-01, -1.0732e-02]],\n",
      "\n",
      "         [[-1.0468e+00, -3.6787e-01, -9.2849e-01],\n",
      "          [ 3.9907e-01, -3.9407e-01,  1.2391e-01],\n",
      "          [ 1.7151e-01,  1.8743e-01,  2.7467e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2155e-01, -5.2855e-01,  5.4503e-01],\n",
      "          [ 3.1334e-01,  2.7901e-01, -7.1918e-01],\n",
      "          [-1.0786e-01,  6.2382e-02, -1.0545e+00]],\n",
      "\n",
      "         [[ 4.2971e-02,  4.8754e-02, -1.4136e-01],\n",
      "          [ 3.0768e-01,  1.7735e-01, -1.3737e-01],\n",
      "          [-1.6426e-01, -1.6286e-02, -5.2706e-02]],\n",
      "\n",
      "         [[-8.2321e-01, -2.7941e-01, -1.2506e-01],\n",
      "          [-6.5513e-01,  8.4959e-01,  2.4028e-02],\n",
      "          [ 7.3980e-01, -1.4132e+00, -4.3206e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6110e-01,  5.6702e-01, -8.6908e-01],\n",
      "          [ 8.6891e-02,  1.7180e-01,  1.1030e+00],\n",
      "          [-2.2753e-01, -9.8340e-01,  2.2991e-01]],\n",
      "\n",
      "         [[ 7.7495e-01, -6.4358e-02, -1.3238e+00],\n",
      "          [-3.4240e-01, -8.2972e-02,  1.0762e+00],\n",
      "          [ 6.4241e-02, -1.0745e+00, -1.0845e+00]],\n",
      "\n",
      "         [[-4.7704e-01, -2.7913e-01, -5.5831e-01],\n",
      "          [ 1.5606e-01, -2.7162e-01,  1.7432e-02],\n",
      "          [ 5.2942e-02,  1.7581e-01,  3.2402e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.5232e-02, -3.3212e-01,  4.0328e-01],\n",
      "          [ 2.1933e-01,  2.5269e-01, -4.6764e-01],\n",
      "          [-1.6584e-01, -3.6591e-02, -7.1823e-01]],\n",
      "\n",
      "         [[ 1.0968e-01,  6.0680e-02, -4.6130e-02],\n",
      "          [ 1.9393e-01,  1.7546e-01, -2.1905e-02],\n",
      "          [-2.6744e-02,  2.9505e-02,  2.8326e-02]],\n",
      "\n",
      "         [[-3.0941e-01, -1.2764e-01, -1.0850e-01],\n",
      "          [-4.6069e-01,  5.0505e-01, -2.1845e-01],\n",
      "          [ 5.0177e-01, -7.3460e-01, -2.3117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3689e-01,  4.4200e-01, -6.8426e-01],\n",
      "          [-2.9094e-03,  6.6353e-03,  9.9815e-01],\n",
      "          [-3.5753e-01, -6.6904e-01,  2.7486e-01]],\n",
      "\n",
      "         [[ 6.5394e-01,  5.8541e-02, -7.1969e-01],\n",
      "          [-2.4439e-01, -8.3710e-02,  8.3098e-01],\n",
      "          [ 3.2060e-02, -8.0152e-01, -1.0915e+00]],\n",
      "\n",
      "         [[-4.4555e-01, -2.4577e-01, -4.0152e-01],\n",
      "          [ 5.1366e-02, -2.8581e-01, -7.6992e-02],\n",
      "          [ 8.9875e-02,  1.2884e-01,  1.1675e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.9122e-02, -6.3151e-01,  4.3500e-01],\n",
      "          [ 1.9524e-01,  9.5895e-02, -6.1780e-01],\n",
      "          [ 2.1478e-02,  1.1629e-02, -1.2381e+00]],\n",
      "\n",
      "         [[ 7.3237e-02, -1.3503e-01, -3.2093e-01],\n",
      "          [ 1.6944e-01,  1.5862e-01, -2.6057e-01],\n",
      "          [ 5.5506e-02,  8.0569e-02, -8.1194e-02]],\n",
      "\n",
      "         [[-6.7378e-01,  6.1861e-02,  1.4788e-01],\n",
      "          [-1.0760e+00,  2.1098e-01,  1.4062e-01],\n",
      "          [ 4.6693e-01, -5.3194e-01,  3.7576e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4845e-01,  3.3379e-01, -4.9144e-02],\n",
      "          [-2.6393e-01,  3.1780e-02,  3.9534e-01],\n",
      "          [-4.1902e-01, -3.2768e-01,  1.8910e-01]],\n",
      "\n",
      "         [[ 3.3736e-01, -3.8723e-01, -8.1062e-01],\n",
      "          [-2.3314e-01, -1.9618e-01,  5.5448e-01],\n",
      "          [ 9.5728e-03, -1.6569e+00, -5.8422e-01]],\n",
      "\n",
      "         [[-1.8696e-01, -1.8962e-01, -1.7133e-01],\n",
      "          [-1.1909e-02,  7.7113e-02,  6.4707e-02],\n",
      "          [-1.8420e-02,  2.9264e-01,  9.1510e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3520e-03, -1.9815e-02,  1.5298e-01],\n",
      "          [ 4.5983e-02,  6.3452e-02, -9.1616e-02],\n",
      "          [-5.5288e-02,  5.6165e-02, -2.4311e-01]],\n",
      "\n",
      "         [[ 1.6921e-01,  9.3495e-02,  3.5639e-02],\n",
      "          [ 1.6870e-01,  5.1893e-02,  5.6022e-02],\n",
      "          [ 2.3560e-02,  1.8266e-02,  7.1451e-02]],\n",
      "\n",
      "         [[ 2.3263e-02, -6.8155e-02, -2.3492e-02],\n",
      "          [-4.3395e-03,  2.5829e-02, -8.1118e-02],\n",
      "          [ 1.7682e-01, -1.6463e-01, -1.8965e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7196e-01,  1.5869e-01, -3.2388e-01],\n",
      "          [-2.7943e-02, -6.2856e-02,  3.3465e-01],\n",
      "          [-3.0270e-01, -4.0899e-01, -2.4413e-02]],\n",
      "\n",
      "         [[ 1.7416e-01,  1.0561e-02, -9.7248e-02],\n",
      "          [-1.2657e-03,  1.1304e-01,  3.2464e-01],\n",
      "          [-1.7914e-01, -4.5066e-01, -5.2970e-01]],\n",
      "\n",
      "         [[-2.7611e-01, -3.0123e-01, -3.6615e-01],\n",
      "          [-1.5432e-02, -1.7239e-01, -1.0005e-01],\n",
      "          [ 1.1070e-01,  1.8147e-01, -1.2016e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8687e-02, -8.5233e-02,  1.5926e-01],\n",
      "          [ 9.2273e-02,  1.6340e-02, -7.8229e-02],\n",
      "          [-1.7906e-02,  1.5363e-02, -1.0096e-01]],\n",
      "\n",
      "         [[ 6.2745e-02,  8.2534e-02,  5.5332e-02],\n",
      "          [ 1.4288e-01,  1.3261e-01, -1.2569e-02],\n",
      "          [-3.2540e-02, -2.4070e-02, -1.5337e-01]],\n",
      "\n",
      "         [[-1.7893e-01, -2.6282e-01, -3.1950e-01],\n",
      "          [-1.3748e-01,  1.6265e-03, -2.6909e-01],\n",
      "          [ 9.5590e-02, -2.2073e-01, -2.4864e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2817e-01,  4.0810e-01, -1.6400e+00],\n",
      "          [ 1.5230e-01,  1.0847e-01,  1.3586e+00],\n",
      "          [ 2.7682e-02, -3.3123e-01,  7.9089e-02]],\n",
      "\n",
      "         [[ 2.2458e-01, -1.3675e-02, -9.8297e-02],\n",
      "          [-6.0367e-02,  4.0426e-02,  2.5543e-01],\n",
      "          [-7.4043e-02, -2.4921e-01, -2.4267e-01]],\n",
      "\n",
      "         [[-7.5500e-01, -4.4247e-01, -6.4121e-01],\n",
      "          [ 2.7062e-01, -3.2792e-01,  7.4009e-02],\n",
      "          [-4.2646e-02,  2.6633e-01,  3.2574e-02]]]], device='cuda:0'), 'conv2.bias': tensor([-0.0008, -0.0334,  0.0258, -0.0439, -0.0027,  0.0344, -0.0201, -0.0046,\n",
      "        -0.0285,  0.0208, -0.0247,  0.0425, -0.0150, -0.0813, -0.0178, -0.0699,\n",
      "         0.0746, -0.0151, -0.0460, -0.0662,  0.0043, -0.0882, -0.0434, -0.0601,\n",
      "        -0.0694, -0.0439, -0.0462, -0.0181, -0.0436,  0.0068,  0.0297, -0.0752],\n",
      "       device='cuda:0'), 'fc1.weight': tensor([[-1.0655e-03,  4.2998e-03,  3.7304e-03,  ..., -4.3035e-06,\n",
      "         -5.3362e-03,  3.5216e-03],\n",
      "        [-5.9911e-03, -4.5830e-03,  2.2128e-03,  ...,  1.8886e-03,\n",
      "          4.3089e-03, -5.8128e-03],\n",
      "        [-2.6138e-03, -3.1124e-03,  3.8560e-03,  ..., -1.7460e-03,\n",
      "          4.2787e-03,  5.1165e-03],\n",
      "        ...,\n",
      "        [ 4.9398e-03, -4.8397e-04, -1.1260e-03,  ...,  6.0001e-03,\n",
      "          5.9945e-03, -5.7187e-03],\n",
      "        [-1.8334e-03, -5.7739e-03,  5.3631e-03,  ..., -1.7580e-03,\n",
      "         -1.2816e-03, -3.8090e-03],\n",
      "        [-7.6416e-04, -2.3158e-05, -3.2976e-03,  ...,  4.2426e-04,\n",
      "         -1.0738e-03,  5.2111e-03]], device='cuda:0'), 'fc1.bias': tensor([ 2.7105e-03, -3.8205e-02, -1.6409e-02, -1.2495e-02,  5.8337e-03,\n",
      "        -6.8573e-03, -8.6617e-03, -2.2330e-02, -1.3518e-02, -2.3196e-03,\n",
      "        -3.4420e-03, -1.3973e-02,  2.4150e-02, -5.8299e-02, -4.3095e-02,\n",
      "        -2.9333e-02, -4.5218e-02, -1.4319e-02, -2.5917e-02, -3.4393e-02,\n",
      "        -5.9874e-03, -1.9300e-02, -3.1581e-03,  3.3489e-03, -2.0620e-02,\n",
      "        -2.5371e-03, -4.3553e-02, -1.7025e-02,  1.7975e-02, -1.4324e-02,\n",
      "        -1.0370e-02, -3.2648e-02, -4.4481e-02,  1.6760e-02, -4.8991e-02,\n",
      "        -4.5616e-02, -2.9876e-02, -1.8375e-02, -2.4897e-02, -6.1466e-02,\n",
      "        -1.4819e-05,  4.2286e-02, -4.1015e-02,  1.3621e-02,  3.4183e-03,\n",
      "        -3.1863e-02, -2.7624e-02, -6.5237e-03, -4.4872e-03,  3.7656e-02,\n",
      "        -1.5208e-02, -6.5561e-03, -6.8895e-03, -3.5800e-02, -5.1309e-03,\n",
      "        -1.7210e-02, -4.6924e-03,  2.8375e-02, -2.5214e-03,  4.2465e-02,\n",
      "        -5.6705e-03, -2.4688e-02,  1.0190e-02, -1.8337e-02, -2.8936e-02,\n",
      "        -8.7393e-02, -9.5802e-03,  1.5645e-03, -3.0424e-02, -1.3046e-02,\n",
      "        -1.4148e-02, -2.5976e-02, -1.9255e-02, -1.6262e-03, -5.7248e-02,\n",
      "        -6.0514e-02, -2.7061e-02, -1.0960e-02, -8.1835e-05, -1.2165e-02,\n",
      "        -5.9458e-03, -2.6406e-02, -4.2264e-03, -4.2273e-02, -2.6200e-02,\n",
      "        -5.2306e-03, -3.8351e-03,  1.7461e-02, -2.6512e-02, -6.5539e-02,\n",
      "        -2.1191e-02, -3.4214e-03, -2.8156e-02, -2.2044e-02, -4.4038e-02,\n",
      "        -4.3571e-03, -9.3593e-03, -2.3576e-02,  8.5193e-03, -1.6448e-03,\n",
      "         8.9888e-05, -3.2216e-02,  1.0503e-02, -3.5137e-02, -2.0311e-02,\n",
      "        -5.7736e-03, -2.4162e-02, -1.6560e-03, -1.0553e-02, -6.3643e-03,\n",
      "         6.1114e-02, -3.8673e-03, -2.3622e-03, -1.2483e-02, -2.1217e-03,\n",
      "        -5.6230e-03, -3.9662e-02, -7.5837e-03, -7.9067e-03, -1.6898e-02,\n",
      "         1.2320e-02, -3.8787e-02, -2.9575e-02, -1.5672e-03, -5.1943e-02,\n",
      "        -8.2814e-03, -1.2645e-02, -4.1698e-02,  1.6868e-04, -1.8792e-02,\n",
      "        -4.4443e-03, -6.1761e-03, -2.9633e-02, -2.2742e-02, -1.2138e-02,\n",
      "         5.6575e-03, -1.6936e-03, -7.3273e-03,  1.3374e-02, -1.6726e-02,\n",
      "        -1.1988e-02,  3.7403e-03,  4.7480e-02, -2.6611e-02, -5.2710e-03,\n",
      "        -2.1895e-02, -2.5075e-02, -5.1810e-02,  7.4558e-03, -2.0430e-02,\n",
      "        -3.4799e-02, -1.5694e-02, -1.8690e-02,  1.1913e-02, -2.0877e-02,\n",
      "        -2.5550e-02, -7.0372e-03, -2.2664e-03, -2.1888e-02, -4.9909e-02,\n",
      "         3.9365e-02, -5.0087e-02, -2.3965e-03,  7.0730e-03, -4.2634e-02,\n",
      "        -5.7229e-04, -4.4713e-02, -5.3750e-02,  7.9296e-03, -2.7365e-02,\n",
      "        -5.0168e-02, -5.9643e-03, -2.7522e-03, -8.5165e-03, -2.2990e-02,\n",
      "         4.3692e-03, -5.8101e-03,  2.5884e-02, -3.7644e-02, -8.8735e-03,\n",
      "        -1.2904e-02, -9.9431e-03, -2.6444e-02,  8.0365e-03,  5.6284e-04,\n",
      "         2.7669e-02,  6.8507e-03, -3.2537e-02, -2.7699e-02, -1.2029e-02,\n",
      "        -4.6619e-02,  1.5277e-02, -2.2786e-03, -3.8419e-03,  5.7394e-03,\n",
      "        -6.5364e-02, -3.8258e-02,  6.1417e-03, -1.0205e-02, -1.0624e-02,\n",
      "        -1.5291e-02, -9.7604e-03,  3.9695e-02, -3.1460e-04,  1.8955e-02,\n",
      "        -1.6483e-02,  4.7912e-02, -5.5285e-03,  1.9551e-02, -1.0199e-02,\n",
      "        -3.5001e-03, -1.0554e-02, -1.1435e-04, -2.4288e-02, -4.9463e-02,\n",
      "        -7.1273e-03, -4.2896e-03, -1.4973e-02, -6.3741e-03, -1.7417e-02,\n",
      "        -1.7968e-02, -3.0255e-02,  5.1651e-02,  7.8672e-04,  1.3668e-02,\n",
      "         1.0845e-02, -5.0228e-02, -3.1098e-03, -1.5021e-02, -7.5132e-03,\n",
      "        -2.3573e-02, -1.2630e-02, -2.5177e-03, -5.4054e-02, -2.8799e-02,\n",
      "         7.0287e-03, -3.9004e-02, -2.5589e-02, -3.4385e-02,  3.9164e-02,\n",
      "        -6.6139e-02, -4.1056e-02, -3.2345e-02, -4.8407e-03, -8.7745e-03,\n",
      "         1.1441e-02, -1.9889e-02, -3.0182e-02, -2.1300e-02,  7.2169e-04,\n",
      "        -4.7249e-03, -2.8438e-02, -4.2806e-02, -1.3754e-02, -1.0273e-02,\n",
      "        -3.2891e-02, -3.5580e-02,  5.0085e-03, -2.3687e-03,  1.0108e-02,\n",
      "        -2.2168e-02, -1.8581e-02, -5.0341e-02, -6.5284e-02, -5.0980e-03,\n",
      "        -1.7255e-03, -6.3995e-03, -3.2084e-02, -1.0724e-02, -2.6098e-02,\n",
      "        -9.1254e-03, -4.7270e-03, -2.1233e-02, -1.7760e-02, -3.9844e-02,\n",
      "        -2.5908e-02, -4.2566e-02,  1.2184e-02, -4.0277e-02, -3.1651e-03,\n",
      "         2.8229e-02,  4.4616e-02, -1.2073e-02, -3.2412e-02, -2.4494e-02,\n",
      "        -2.7060e-02, -4.5700e-03, -5.5233e-02, -1.4612e-02, -7.3947e-03,\n",
      "        -5.7721e-02, -5.7414e-02, -1.0259e-03, -3.7860e-02, -3.5311e-02,\n",
      "        -4.8721e-02,  1.7116e-03, -7.3676e-03, -1.7483e-02, -1.0685e-02,\n",
      "        -6.4261e-02, -5.2887e-03, -1.2143e-02, -2.6563e-05, -6.1638e-02,\n",
      "        -2.2869e-03, -8.1403e-03, -3.8691e-02, -6.1435e-02, -2.1574e-02,\n",
      "         1.7225e-04,  3.0626e-02,  1.3566e-02, -7.3413e-03, -1.0694e-02,\n",
      "        -2.5161e-02, -1.3865e-02,  2.1346e-02, -5.1089e-02,  1.3547e-02,\n",
      "        -3.6265e-02,  4.9594e-02,  1.7155e-02, -2.0880e-02, -3.8493e-02,\n",
      "        -1.6615e-02, -3.9157e-02, -4.6403e-03,  1.0636e-02, -2.0920e-02,\n",
      "        -8.6317e-03, -3.0501e-02, -8.4924e-03, -9.9828e-03, -7.0515e-03,\n",
      "         3.5213e-03, -4.3828e-02, -9.8370e-03, -2.3760e-03,  9.8672e-03,\n",
      "         1.4565e-02, -2.5355e-03, -6.7829e-04, -5.5202e-02, -2.5522e-02,\n",
      "        -1.3456e-02,  3.5020e-02, -4.2759e-04, -2.9271e-03, -9.5901e-03,\n",
      "        -1.8443e-03, -4.0829e-02, -5.3714e-02, -6.8029e-03, -9.4881e-03,\n",
      "        -3.3810e-02, -1.0010e-02,  8.6882e-03, -7.3804e-04,  1.4701e-04,\n",
      "        -6.7708e-03, -3.1181e-02, -1.6195e-02,  1.6931e-02, -3.7093e-03,\n",
      "        -1.2204e-02, -1.7220e-02, -1.2830e-02, -2.7564e-02,  7.5766e-03,\n",
      "         1.2764e-02, -1.3106e-02,  2.4777e-02,  1.5253e-02, -3.5094e-02,\n",
      "        -2.4807e-02, -5.0857e-02, -1.3568e-04, -1.1200e-02, -3.3890e-02,\n",
      "        -1.0639e-02, -2.5451e-02, -3.4757e-02,  2.6912e-03, -4.5591e-02,\n",
      "         4.0715e-02, -9.2182e-03,  1.6178e-03, -3.8818e-02, -6.3303e-03,\n",
      "        -7.8262e-04, -1.2294e-02, -4.0582e-02, -7.1195e-02, -8.5003e-03,\n",
      "         5.5385e-03, -3.1782e-02, -8.3485e-03, -2.2000e-02,  9.2426e-03,\n",
      "         1.4349e-02, -1.6918e-02, -1.1073e-02, -3.8902e-02,  1.0054e-02,\n",
      "        -1.2785e-02, -2.7355e-02,  1.6023e-02,  2.7795e-02, -3.1946e-02,\n",
      "        -1.1642e-02, -9.9371e-03, -6.8537e-02, -4.7026e-03, -1.2529e-02,\n",
      "        -1.2326e-02, -4.9070e-02, -9.1302e-03,  2.0323e-03, -2.4095e-03,\n",
      "        -6.7185e-03, -1.6806e-02, -2.4743e-02, -2.3063e-02, -7.6520e-03,\n",
      "         6.9399e-03, -1.5582e-02,  6.4597e-03, -2.6836e-02, -1.9800e-02,\n",
      "        -2.9541e-02,  2.1761e-02, -7.5621e-04, -1.3436e-02, -4.7947e-02,\n",
      "        -5.7867e-03,  4.7417e-03, -4.7656e-03, -5.5684e-02, -1.8612e-02,\n",
      "        -5.1121e-03, -3.0519e-02, -4.5961e-02, -3.1593e-03, -1.1651e-02,\n",
      "         9.6760e-03, -1.4937e-02, -2.8990e-02, -2.2321e-03,  1.0259e-04,\n",
      "        -1.8091e-02, -7.5619e-03, -5.9281e-03,  3.8544e-02, -6.5528e-02,\n",
      "        -8.8359e-03,  2.2744e-04, -9.0606e-03, -3.5255e-03, -5.0913e-04,\n",
      "         7.3705e-03, -1.2538e-02,  8.4548e-04, -7.7750e-02, -2.8084e-02,\n",
      "         7.6184e-03, -7.4961e-03, -1.3264e-05, -1.0810e-02, -2.6143e-02,\n",
      "        -1.3923e-02, -3.6908e-02, -2.9113e-02, -3.0399e-02,  7.0166e-02,\n",
      "         1.3856e-02, -1.5619e-02,  8.6806e-03,  8.1511e-03,  1.2002e-03,\n",
      "        -6.3016e-03, -1.8869e-02,  7.6046e-03, -4.3703e-03, -2.3872e-02,\n",
      "        -1.0049e-02, -1.1850e-03, -1.1617e-02, -8.7524e-03, -2.7435e-02,\n",
      "        -6.1499e-03, -2.7926e-02, -1.1723e-04, -3.4402e-02,  8.3555e-03,\n",
      "         2.6400e-02,  3.8340e-03,  3.1416e-02, -2.0962e-02, -1.9020e-02,\n",
      "        -1.6989e-02,  1.7023e-02,  1.1743e-03, -1.7791e-02,  9.7156e-04,\n",
      "        -1.8116e-03, -4.1632e-02, -3.8272e-02, -8.6096e-03, -6.1964e-03,\n",
      "         2.5232e-03,  3.7116e-02], device='cuda:0'), 'fc2.weight': tensor([[ 0.0887, -0.0366, -0.1510,  ...,  0.0557,  0.0983, -0.0711],\n",
      "        [ 0.0144, -0.0381,  0.0499,  ...,  0.0013,  0.0223,  0.0567],\n",
      "        [-0.1912,  0.0040,  0.0221,  ...,  0.0717,  0.0536, -0.2441],\n",
      "        ...,\n",
      "        [ 0.0758, -0.0733, -0.1171,  ..., -0.0550, -0.0170,  0.1066],\n",
      "        [-0.0604,  0.0643, -0.0200,  ...,  0.0046,  0.0414, -0.1302],\n",
      "        [-0.0232, -0.0958, -0.0909,  ..., -0.0288,  0.0693,  0.0695]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([-0.0391,  0.0170, -0.0094,  0.0580, -0.0089,  0.0123,  0.0071, -0.0274,\n",
      "        -0.0077, -0.0083], device='cuda:0')})\n"
     ]
    }
   ],
   "execution_count": 477
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:32:39.346395Z",
     "start_time": "2025-03-31T14:32:39.337721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# secret_key = torch.load(\"secret_key.pth\")\n",
    "# watermark_vector=torch.tensor([0., 1., 0., 1., 1., 0., 0., 1.], dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "      conv2_mean = model_prun.conv2.weight.mean(dim=0)  # Should be (1,3,3)\n",
    "      conv2_mean_flat = conv2_mean.view(-1)\n",
    "      extracted_watermark = torch.sigmoid(torch.matmul( wm_regularizer.secret_key.cpu(), conv2_mean_flat.cpu()))  # Fix dimensions\n",
    "      extracted_watermark_binary = (extracted_watermark > 0.5).float()\n",
    "\n",
    "      # print(type(extracted_watermark_binary))\n",
    "      # print(type(watermark_vector))\n",
    "      #\n",
    "      # print(\"\\nOriginal Watermark:\", watermark_vector.cpu().numpy())\n",
    "      # print(\"\\nExtracted Watermark:\", extracted_watermark_binary.cpu().numpy())\n",
    "      print(\"\\nBER\", compute_ber(watermark_vector.cpu(), extracted_watermark_binary.cpu()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BER 0.0\n"
     ]
    }
   ],
   "execution_count": 478
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JyTNPP90MxsL",
    "ExecuteTime": {
     "end_time": "2025-03-31T14:32:40.054965Z",
     "start_time": "2025-03-31T14:32:39.820674Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "def prune_smallest_percentage(model, percentage=0.1):\n",
    "    # Loop through model layers and prune based on smallest weights\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            weight_tensor = module.weight.data\n",
    "\n",
    "            # Get the absolute value of weights and sort them\n",
    "            abs_weights = torch.abs(weight_tensor).view(-1)  # Flatten to 1D\n",
    "            sorted_weights, indices = torch.sort(abs_weights)  # Sort by absolute values\n",
    "            print('sorted_weights')\n",
    "            print(sorted_weights)\n",
    "\n",
    "            # Calculate the threshold for the smallest 'percentage' of weights\n",
    "            print(torch.max(sorted_weights))\n",
    "            num_weights_to_prune = int((len(sorted_weights) * percentage))\n",
    "            print('num_weights_to_prune')\n",
    "            print(num_weights_to_prune)\n",
    "            if num_weights_to_prune == len(sorted_weights):\n",
    "                threshold = sorted_weights[num_weights_to_prune-1]\n",
    "            else:\n",
    "                threshold = sorted_weights[num_weights_to_prune]\n",
    "            print(threshold)\n",
    "            print('threshold')\n",
    "\n",
    "            # Create a pruning mask: set weights smaller than the threshold to zero\n",
    "            mask = torch.abs(weight_tensor) < threshold\n",
    "\n",
    "            # Apply the mask to prune weights\n",
    "            weight_tensor1=weight_tensor\n",
    "            print(weight_tensor)\n",
    "            print('weight_tensor1')\n",
    "            weight_tensor[mask] = 0\n",
    "            print(weight_tensor)\n",
    "            print('weight_tensor')\n",
    "\n",
    "            print(\"\\nBER\", compute_ber(weight_tensor1.cpu(), weight_tensor.cpu()))\n",
    "\n",
    "\n",
    "            # Optionally, you can apply pruning to the layer (keeping track of mask)\n",
    "            # prune.custom_from_mask(module, 'weight', mask)\n",
    "            print(f\"Pruned {num_weights_to_prune} weights in layer {name}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_prun1= prune_smallest_percentage(model_copy, percentage=0.9)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_weights\n",
      "tensor([4.4517e-04, 1.6061e-03, 5.3799e-03, 5.8576e-03, 6.1945e-03, 7.8297e-03,\n",
      "        1.4069e-02, 1.5813e-02, 1.8121e-02, 2.0413e-02, 2.1635e-02, 2.2026e-02,\n",
      "        2.4171e-02, 2.6004e-02, 2.8463e-02, 2.9274e-02, 3.0556e-02, 3.2284e-02,\n",
      "        3.3530e-02, 3.7204e-02, 3.7219e-02, 3.7738e-02, 3.9321e-02, 3.9522e-02,\n",
      "        4.0164e-02, 4.4925e-02, 4.8270e-02, 4.8611e-02, 5.3598e-02, 5.4223e-02,\n",
      "        5.6993e-02, 5.7403e-02, 5.8822e-02, 6.1274e-02, 6.1337e-02, 6.1549e-02,\n",
      "        6.2094e-02, 6.2481e-02, 6.4254e-02, 6.6871e-02, 6.7383e-02, 6.9042e-02,\n",
      "        7.1862e-02, 7.4154e-02, 7.4517e-02, 7.7136e-02, 7.7190e-02, 8.3049e-02,\n",
      "        8.4193e-02, 8.7263e-02, 8.7557e-02, 8.8799e-02, 9.0421e-02, 9.1848e-02,\n",
      "        9.4727e-02, 9.5594e-02, 9.5634e-02, 9.8159e-02, 9.8693e-02, 1.0134e-01,\n",
      "        1.0181e-01, 1.0194e-01, 1.0442e-01, 1.0641e-01, 1.0927e-01, 1.0964e-01,\n",
      "        1.0984e-01, 1.1090e-01, 1.1173e-01, 1.1256e-01, 1.1463e-01, 1.1502e-01,\n",
      "        1.1600e-01, 1.1791e-01, 1.1981e-01, 1.2028e-01, 1.2042e-01, 1.2149e-01,\n",
      "        1.2278e-01, 1.2456e-01, 1.2626e-01, 1.2648e-01, 1.2696e-01, 1.2699e-01,\n",
      "        1.2720e-01, 1.2779e-01, 1.2858e-01, 1.2986e-01, 1.2991e-01, 1.3090e-01,\n",
      "        1.3377e-01, 1.3651e-01, 1.3726e-01, 1.3909e-01, 1.3916e-01, 1.4020e-01,\n",
      "        1.4115e-01, 1.4180e-01, 1.4265e-01, 1.4430e-01, 1.4431e-01, 1.4721e-01,\n",
      "        1.4732e-01, 1.4773e-01, 1.5075e-01, 1.5108e-01, 1.5320e-01, 1.5345e-01,\n",
      "        1.5483e-01, 1.5546e-01, 1.5676e-01, 1.5755e-01, 1.6041e-01, 1.6163e-01,\n",
      "        1.6188e-01, 1.6215e-01, 1.6309e-01, 1.6370e-01, 1.6492e-01, 1.6583e-01,\n",
      "        1.6649e-01, 1.6660e-01, 1.6765e-01, 1.7566e-01, 1.7629e-01, 1.7720e-01,\n",
      "        1.7762e-01, 1.7847e-01, 1.7886e-01, 1.7902e-01, 1.8110e-01, 1.8267e-01,\n",
      "        1.8383e-01, 1.8403e-01, 1.8433e-01, 1.8528e-01, 1.8596e-01, 1.8684e-01,\n",
      "        1.8720e-01, 1.9011e-01, 1.9125e-01, 1.9240e-01, 1.9650e-01, 1.9680e-01,\n",
      "        1.9795e-01, 1.9873e-01, 2.0139e-01, 2.0427e-01, 2.0514e-01, 2.0720e-01,\n",
      "        2.0874e-01, 2.0900e-01, 2.0916e-01, 2.0938e-01, 2.0981e-01, 2.1018e-01,\n",
      "        2.1199e-01, 2.1261e-01, 2.1368e-01, 2.1472e-01, 2.1551e-01, 2.1615e-01,\n",
      "        2.1754e-01, 2.1912e-01, 2.2014e-01, 2.2586e-01, 2.2737e-01, 2.3061e-01,\n",
      "        2.3450e-01, 2.3514e-01, 2.3799e-01, 2.3850e-01, 2.4254e-01, 2.4612e-01,\n",
      "        2.4706e-01, 2.4714e-01, 2.4882e-01, 2.4895e-01, 2.4983e-01, 2.5059e-01,\n",
      "        2.5090e-01, 2.5322e-01, 2.5478e-01, 2.5558e-01, 2.5649e-01, 2.5709e-01,\n",
      "        2.6014e-01, 2.6219e-01, 2.6333e-01, 2.6479e-01, 2.6501e-01, 2.6576e-01,\n",
      "        2.6590e-01, 2.6643e-01, 2.6717e-01, 2.6801e-01, 2.6817e-01, 2.7007e-01,\n",
      "        2.7132e-01, 2.7287e-01, 2.7541e-01, 2.7570e-01, 2.7636e-01, 2.7655e-01,\n",
      "        2.7828e-01, 2.7878e-01, 2.7934e-01, 2.8125e-01, 2.8286e-01, 2.8523e-01,\n",
      "        2.8542e-01, 2.8598e-01, 2.8669e-01, 2.8820e-01, 2.8873e-01, 2.8890e-01,\n",
      "        2.9214e-01, 2.9220e-01, 2.9226e-01, 2.9487e-01, 2.9774e-01, 2.9805e-01,\n",
      "        3.0082e-01, 3.0413e-01, 3.0520e-01, 3.0528e-01, 3.0569e-01, 3.0581e-01,\n",
      "        3.1131e-01, 3.1149e-01, 3.1283e-01, 3.1303e-01, 3.1438e-01, 3.1669e-01,\n",
      "        3.1794e-01, 3.2067e-01, 3.2265e-01, 3.2802e-01, 3.2970e-01, 3.3209e-01,\n",
      "        3.3438e-01, 3.3750e-01, 3.3766e-01, 3.3797e-01, 3.3938e-01, 3.3943e-01,\n",
      "        3.4488e-01, 3.4592e-01, 3.4658e-01, 3.4701e-01, 3.5031e-01, 3.5592e-01,\n",
      "        3.5994e-01, 3.6358e-01, 3.6451e-01, 3.6473e-01, 3.6647e-01, 3.6648e-01,\n",
      "        3.6664e-01, 3.6710e-01, 3.7533e-01, 3.7538e-01, 3.7578e-01, 3.7641e-01,\n",
      "        3.7728e-01, 3.7917e-01, 3.8180e-01, 3.8284e-01, 3.8286e-01, 3.8625e-01,\n",
      "        3.9064e-01, 4.0007e-01, 4.0074e-01, 4.0233e-01, 4.0724e-01, 4.1460e-01,\n",
      "        4.1591e-01, 4.1665e-01, 4.1792e-01, 4.2348e-01, 4.2987e-01, 4.3104e-01,\n",
      "        4.3302e-01, 4.3437e-01, 4.6331e-01, 4.6657e-01, 4.7248e-01, 4.9804e-01],\n",
      "       device='cuda:0')\n",
      "tensor(0.4980, device='cuda:0')\n",
      "num_weights_to_prune\n",
      "259\n",
      "tensor(0.3671, device='cuda:0')\n",
      "threshold\n",
      "tensor([[[[ 3.0413e-01,  4.3302e-01, -1.8403e-01],\n",
      "          [-1.2042e-01,  1.7566e-01, -1.2720e-01],\n",
      "          [ 6.7383e-02, -5.6993e-02, -1.9650e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2970e-01,  1.3909e-01,  2.8890e-01],\n",
      "          [ 2.4254e-01, -1.5755e-01, -3.7578e-01],\n",
      "          [-2.3799e-01, -3.4658e-01, -2.1368e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6333e-01,  1.1173e-01,  2.1912e-01],\n",
      "          [-1.0194e-01,  1.2858e-01,  3.6664e-01],\n",
      "          [-4.3104e-01, -4.1460e-01,  3.6451e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1791e-01,  2.0427e-01, -4.3437e-01],\n",
      "          [ 8.8799e-02,  2.7934e-01, -4.0074e-01],\n",
      "          [ 1.0964e-01,  2.7541e-01,  9.8159e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9522e-02, -1.8267e-01, -4.1591e-01],\n",
      "          [ 1.5676e-01,  1.1256e-01, -2.4714e-01],\n",
      "          [ 1.7886e-01,  1.5345e-01, -2.4612e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1463e-01, -2.9220e-01,  2.2014e-01],\n",
      "          [ 1.8528e-01, -1.4020e-01, -7.7190e-02],\n",
      "          [-3.4701e-01, -2.4706e-01,  1.6660e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4254e-02,  1.9011e-01, -2.6717e-01],\n",
      "          [ 2.0139e-01, -4.1792e-01,  4.0164e-02],\n",
      "          [ 1.7847e-01, -2.9487e-01,  1.5483e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1981e-01,  2.1635e-02,  2.3061e-01],\n",
      "          [ 3.1149e-01,  3.3943e-01,  8.3049e-02],\n",
      "          [ 1.3916e-01,  2.0720e-01,  1.8383e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1669e-01,  1.1600e-01, -5.8576e-03],\n",
      "          [-2.0938e-01,  5.8822e-02,  1.6215e-01],\n",
      "          [ 2.1551e-01, -2.5478e-01,  9.0421e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5558e-01,  3.2284e-02,  2.6801e-01],\n",
      "          [ 3.3750e-01, -2.0981e-01, -2.3450e-01],\n",
      "          [ 2.7132e-01, -3.3797e-01, -2.6004e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0984e-01, -2.6576e-01, -3.6710e-01],\n",
      "          [-2.4983e-01, -4.8270e-02,  2.1199e-01],\n",
      "          [ 3.1303e-01, -8.7557e-02,  2.7878e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0007e-01, -1.5546e-01, -3.7219e-02],\n",
      "          [-3.1283e-01, -4.4517e-04,  2.8669e-01],\n",
      "          [-2.3850e-01,  3.0528e-01,  2.6590e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8433e-01, -8.4193e-02, -2.5090e-01],\n",
      "          [ 6.1337e-02, -2.6014e-01,  1.2028e-01],\n",
      "          [-2.7007e-01, -1.4069e-02,  2.8598e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1472e-01, -4.2987e-01, -3.7538e-01],\n",
      "          [ 3.8284e-01,  1.4180e-01, -3.7738e-02],\n",
      "          [ 1.3726e-01,  2.1754e-01,  5.4223e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0581e-01, -4.9804e-01,  2.1615e-01],\n",
      "          [-8.7263e-02, -1.7762e-01,  4.2348e-01],\n",
      "          [-3.7641e-01,  7.1862e-02,  1.4430e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.4154e-02, -7.7136e-02,  5.3799e-03],\n",
      "          [-1.5320e-01, -1.2278e-01, -2.2586e-01],\n",
      "          [-2.1018e-01,  2.8125e-01,  6.1945e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.0520e-01,  1.5813e-02, -1.9240e-01],\n",
      "          [-1.6061e-03,  1.2149e-01, -1.2648e-01],\n",
      "          [ 5.7403e-02,  1.8121e-02, -1.0134e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1848e-02, -2.1261e-01,  1.2779e-01],\n",
      "          [-2.7655e-01,  2.6501e-01,  2.4895e-01],\n",
      "          [-1.2696e-01,  2.4882e-01, -3.4592e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4517e-02,  3.5031e-01,  3.1131e-01],\n",
      "          [-4.1665e-01, -2.8873e-01,  1.0442e-01],\n",
      "          [-1.6583e-01,  3.0569e-01, -1.3651e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6648e-01, -1.0181e-01, -4.7248e-01],\n",
      "          [-2.0916e-01, -3.3438e-01,  1.6765e-01],\n",
      "          [ 1.3090e-01,  1.2699e-01,  9.5634e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.1274e-02, -1.0927e-01,  6.1549e-02],\n",
      "          [-3.9321e-02,  1.9125e-01, -3.1438e-01],\n",
      "          [-2.8286e-01,  3.3209e-01, -1.7902e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5108e-01,  1.2991e-01,  2.0874e-01],\n",
      "          [-3.8286e-01, -2.6219e-01,  1.1090e-01],\n",
      "          [-6.6871e-02, -1.8596e-01, -3.1794e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5592e-01,  2.9774e-01,  1.6309e-01],\n",
      "          [-1.1502e-01, -1.0641e-01, -1.4265e-01],\n",
      "          [-2.7828e-01, -2.9805e-01,  1.4115e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5709e-01, -2.0413e-02, -4.6657e-01],\n",
      "          [-1.8110e-01,  2.7570e-01, -1.9795e-01],\n",
      "          [-2.2737e-01,  2.8542e-01,  3.0082e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3938e-01, -3.6358e-01, -5.3598e-02],\n",
      "          [-6.2481e-02, -1.2456e-01,  2.6479e-01],\n",
      "          [ 2.9214e-01, -2.8463e-02,  2.6817e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6188e-01, -3.4488e-01,  9.5594e-02],\n",
      "          [-1.8720e-01,  1.4773e-01,  9.8693e-02],\n",
      "          [ 1.9680e-01,  2.8820e-01, -1.4721e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2094e-02, -6.9042e-02, -2.9274e-02],\n",
      "          [ 3.5994e-01,  1.7629e-01, -3.6647e-01],\n",
      "          [-3.9064e-01, -1.6649e-01,  4.0233e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2986e-01, -2.5649e-01,  2.5322e-01],\n",
      "          [-2.4171e-02, -4.4925e-02, -2.6643e-01],\n",
      "          [ 3.0556e-02,  1.6163e-01, -1.6492e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7636e-01,  1.2626e-01,  3.2265e-01],\n",
      "          [ 2.0514e-01,  1.6370e-01, -7.8297e-03],\n",
      "          [-2.3514e-01, -3.7728e-01, -3.8625e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2026e-02, -2.5059e-01,  3.7204e-02],\n",
      "          [-1.9873e-01, -1.8684e-01,  4.0724e-01],\n",
      "          [-2.9226e-01, -2.8523e-01,  3.2802e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3766e-01,  1.5075e-01,  9.4727e-02],\n",
      "          [ 3.8180e-01,  3.7533e-01,  1.7720e-01],\n",
      "          [-1.4431e-01,  3.3530e-02, -4.6331e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0900e-01, -3.2067e-01,  1.6041e-01],\n",
      "          [-1.4732e-01, -2.7287e-01, -3.7917e-01],\n",
      "          [-3.6473e-01,  4.8611e-02, -1.3377e-01]]]], device='cuda:0')\n",
      "weight_tensor1\n",
      "tensor([[[[ 0.0000,  0.4330,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.3758],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.4310, -0.4146,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.4344],\n",
      "          [ 0.0000,  0.0000, -0.4007],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.4159],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.4179,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.3671],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.4001,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.4299, -0.3754],\n",
      "          [ 0.3828,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.4980,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.4235],\n",
      "          [-0.3764,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.4167,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.4725],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.3829,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.4666],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.3906,  0.0000,  0.4023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.3773, -0.3862]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.4072],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.3818,  0.3753,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.4633]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.3792],\n",
      "          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')\n",
      "weight_tensor\n",
      "\n",
      "BER 0.0\n",
      "Pruned 259 weights in layer conv1\n",
      "sorted_weights\n",
      "tensor([2.1244e-05, 2.5481e-05, 5.8853e-05,  ..., 2.4569e+00, 2.5227e+00,\n",
      "        2.5388e+00], device='cuda:0')\n",
      "tensor(2.5388, device='cuda:0')\n",
      "num_weights_to_prune\n",
      "8294\n",
      "tensor(0.5857, device='cuda:0')\n",
      "threshold\n",
      "tensor([[[[-8.9108e-03, -2.3986e-01,  2.5394e-01],\n",
      "          [ 2.0963e-01,  1.0155e-01, -1.9567e-01],\n",
      "          [ 3.0319e-02,  3.9939e-02, -1.7175e-01]],\n",
      "\n",
      "         [[ 9.0353e-02, -1.2196e-01, -1.5819e-01],\n",
      "          [ 1.9754e-01, -1.6897e-02, -2.3974e-01],\n",
      "          [-2.1843e-01, -1.2314e-01, -1.2947e-01]],\n",
      "\n",
      "         [[-1.7323e-01, -1.7456e-01, -8.4748e-02],\n",
      "          [-7.1420e-02,  1.1860e-01, -2.5320e-02],\n",
      "          [ 1.8962e-01, -1.4106e-01, -7.5248e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3654e-01,  4.1491e-01, -5.5369e-01],\n",
      "          [-1.1298e-01,  4.6818e-02,  8.5527e-01],\n",
      "          [-2.7313e-01, -6.2151e-01,  4.8367e-02]],\n",
      "\n",
      "         [[ 4.1242e-01, -1.9455e-01, -3.8205e-01],\n",
      "          [-1.6556e-01, -5.0334e-02,  3.3277e-01],\n",
      "          [-3.3255e-02, -1.7340e-01, -1.0732e-02]],\n",
      "\n",
      "         [[-1.0468e+00, -3.6787e-01, -9.2849e-01],\n",
      "          [ 3.9907e-01, -3.9407e-01,  1.2391e-01],\n",
      "          [ 1.7151e-01,  1.8743e-01,  2.7467e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2155e-01, -5.2855e-01,  5.4503e-01],\n",
      "          [ 3.1334e-01,  2.7901e-01, -7.1918e-01],\n",
      "          [-1.0786e-01,  6.2382e-02, -1.0545e+00]],\n",
      "\n",
      "         [[ 4.2971e-02,  4.8754e-02, -1.4136e-01],\n",
      "          [ 3.0768e-01,  1.7735e-01, -1.3737e-01],\n",
      "          [-1.6426e-01, -1.6286e-02, -5.2706e-02]],\n",
      "\n",
      "         [[-8.2321e-01, -2.7941e-01, -1.2506e-01],\n",
      "          [-6.5513e-01,  8.4959e-01,  2.4028e-02],\n",
      "          [ 7.3980e-01, -1.4132e+00, -4.3206e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6110e-01,  5.6702e-01, -8.6908e-01],\n",
      "          [ 8.6891e-02,  1.7180e-01,  1.1030e+00],\n",
      "          [-2.2753e-01, -9.8340e-01,  2.2991e-01]],\n",
      "\n",
      "         [[ 7.7495e-01, -6.4358e-02, -1.3238e+00],\n",
      "          [-3.4240e-01, -8.2972e-02,  1.0762e+00],\n",
      "          [ 6.4241e-02, -1.0745e+00, -1.0845e+00]],\n",
      "\n",
      "         [[-4.7704e-01, -2.7913e-01, -5.5831e-01],\n",
      "          [ 1.5606e-01, -2.7162e-01,  1.7432e-02],\n",
      "          [ 5.2942e-02,  1.7581e-01,  3.2402e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.5232e-02, -3.3212e-01,  4.0328e-01],\n",
      "          [ 2.1933e-01,  2.5269e-01, -4.6764e-01],\n",
      "          [-1.6584e-01, -3.6591e-02, -7.1823e-01]],\n",
      "\n",
      "         [[ 1.0968e-01,  6.0680e-02, -4.6130e-02],\n",
      "          [ 1.9393e-01,  1.7546e-01, -2.1905e-02],\n",
      "          [-2.6744e-02,  2.9505e-02,  2.8326e-02]],\n",
      "\n",
      "         [[-3.0941e-01, -1.2764e-01, -1.0850e-01],\n",
      "          [-4.6069e-01,  5.0505e-01, -2.1845e-01],\n",
      "          [ 5.0177e-01, -7.3460e-01, -2.3117e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3689e-01,  4.4200e-01, -6.8426e-01],\n",
      "          [-2.9094e-03,  6.6353e-03,  9.9815e-01],\n",
      "          [-3.5753e-01, -6.6904e-01,  2.7486e-01]],\n",
      "\n",
      "         [[ 6.5394e-01,  5.8541e-02, -7.1969e-01],\n",
      "          [-2.4439e-01, -8.3710e-02,  8.3098e-01],\n",
      "          [ 3.2060e-02, -8.0152e-01, -1.0915e+00]],\n",
      "\n",
      "         [[-4.4555e-01, -2.4577e-01, -4.0152e-01],\n",
      "          [ 5.1366e-02, -2.8581e-01, -7.6992e-02],\n",
      "          [ 8.9875e-02,  1.2884e-01,  1.1675e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.9122e-02, -6.3151e-01,  4.3500e-01],\n",
      "          [ 1.9524e-01,  9.5895e-02, -6.1780e-01],\n",
      "          [ 2.1478e-02,  1.1629e-02, -1.2381e+00]],\n",
      "\n",
      "         [[ 7.3237e-02, -1.3503e-01, -3.2093e-01],\n",
      "          [ 1.6944e-01,  1.5862e-01, -2.6057e-01],\n",
      "          [ 5.5506e-02,  8.0569e-02, -8.1194e-02]],\n",
      "\n",
      "         [[-6.7378e-01,  6.1861e-02,  1.4788e-01],\n",
      "          [-1.0760e+00,  2.1098e-01,  1.4062e-01],\n",
      "          [ 4.6693e-01, -5.3194e-01,  3.7576e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4845e-01,  3.3379e-01, -4.9144e-02],\n",
      "          [-2.6393e-01,  3.1780e-02,  3.9534e-01],\n",
      "          [-4.1902e-01, -3.2768e-01,  1.8910e-01]],\n",
      "\n",
      "         [[ 3.3736e-01, -3.8723e-01, -8.1062e-01],\n",
      "          [-2.3314e-01, -1.9618e-01,  5.5448e-01],\n",
      "          [ 9.5728e-03, -1.6569e+00, -5.8422e-01]],\n",
      "\n",
      "         [[-1.8696e-01, -1.8962e-01, -1.7133e-01],\n",
      "          [-1.1909e-02,  7.7113e-02,  6.4707e-02],\n",
      "          [-1.8420e-02,  2.9264e-01,  9.1510e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3520e-03, -1.9815e-02,  1.5298e-01],\n",
      "          [ 4.5983e-02,  6.3452e-02, -9.1616e-02],\n",
      "          [-5.5288e-02,  5.6165e-02, -2.4311e-01]],\n",
      "\n",
      "         [[ 1.6921e-01,  9.3495e-02,  3.5639e-02],\n",
      "          [ 1.6870e-01,  5.1893e-02,  5.6022e-02],\n",
      "          [ 2.3560e-02,  1.8266e-02,  7.1451e-02]],\n",
      "\n",
      "         [[ 2.3263e-02, -6.8155e-02, -2.3492e-02],\n",
      "          [-4.3395e-03,  2.5829e-02, -8.1118e-02],\n",
      "          [ 1.7682e-01, -1.6463e-01, -1.8965e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7196e-01,  1.5869e-01, -3.2388e-01],\n",
      "          [-2.7943e-02, -6.2856e-02,  3.3465e-01],\n",
      "          [-3.0270e-01, -4.0899e-01, -2.4413e-02]],\n",
      "\n",
      "         [[ 1.7416e-01,  1.0561e-02, -9.7248e-02],\n",
      "          [-1.2657e-03,  1.1304e-01,  3.2464e-01],\n",
      "          [-1.7914e-01, -4.5066e-01, -5.2970e-01]],\n",
      "\n",
      "         [[-2.7611e-01, -3.0123e-01, -3.6615e-01],\n",
      "          [-1.5432e-02, -1.7239e-01, -1.0005e-01],\n",
      "          [ 1.1070e-01,  1.8147e-01, -1.2016e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8687e-02, -8.5233e-02,  1.5926e-01],\n",
      "          [ 9.2273e-02,  1.6340e-02, -7.8229e-02],\n",
      "          [-1.7906e-02,  1.5363e-02, -1.0096e-01]],\n",
      "\n",
      "         [[ 6.2745e-02,  8.2534e-02,  5.5332e-02],\n",
      "          [ 1.4288e-01,  1.3261e-01, -1.2569e-02],\n",
      "          [-3.2540e-02, -2.4070e-02, -1.5337e-01]],\n",
      "\n",
      "         [[-1.7893e-01, -2.6282e-01, -3.1950e-01],\n",
      "          [-1.3748e-01,  1.6265e-03, -2.6909e-01],\n",
      "          [ 9.5590e-02, -2.2073e-01, -2.4864e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2817e-01,  4.0810e-01, -1.6400e+00],\n",
      "          [ 1.5230e-01,  1.0847e-01,  1.3586e+00],\n",
      "          [ 2.7682e-02, -3.3123e-01,  7.9089e-02]],\n",
      "\n",
      "         [[ 2.2458e-01, -1.3675e-02, -9.8297e-02],\n",
      "          [-6.0367e-02,  4.0426e-02,  2.5543e-01],\n",
      "          [-7.4043e-02, -2.4921e-01, -2.4267e-01]],\n",
      "\n",
      "         [[-7.5500e-01, -4.4247e-01, -6.4121e-01],\n",
      "          [ 2.7062e-01, -3.2792e-01,  7.4009e-02],\n",
      "          [-4.2646e-02,  2.6633e-01,  3.2574e-02]]]], device='cuda:0')\n",
      "weight_tensor1\n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.8553],\n",
      "          [ 0.0000, -0.6215,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.0468,  0.0000, -0.9285],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.7192],\n",
      "          [ 0.0000,  0.0000, -1.0545]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.8232,  0.0000,  0.0000],\n",
      "          [-0.6551,  0.8496,  0.0000],\n",
      "          [ 0.7398, -1.4132,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7611,  0.0000, -0.8691],\n",
      "          [ 0.0000,  0.0000,  1.1030],\n",
      "          [ 0.0000, -0.9834,  0.0000]],\n",
      "\n",
      "         [[ 0.7749,  0.0000, -1.3238],\n",
      "          [ 0.0000,  0.0000,  1.0762],\n",
      "          [ 0.0000, -1.0745, -1.0845]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.7182]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.7346,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.6843],\n",
      "          [ 0.0000,  0.0000,  0.9982],\n",
      "          [ 0.0000, -0.6690,  0.0000]],\n",
      "\n",
      "         [[ 0.6539,  0.0000, -0.7197],\n",
      "          [ 0.0000,  0.0000,  0.8310],\n",
      "          [ 0.0000, -0.8015, -1.0915]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.6315,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.6178],\n",
      "          [ 0.0000,  0.0000, -1.2381]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.6738,  0.0000,  0.0000],\n",
      "          [-1.0760,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.8106],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -1.6569,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -1.6400],\n",
      "          [ 0.0000,  0.0000,  1.3586],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.7550,  0.0000, -0.6412],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')\n",
      "weight_tensor\n",
      "\n",
      "BER 0.0\n",
      "Pruned 8294 weights in layer conv2\n",
      "sorted_weights\n",
      "tensor([3.6526e-09, 5.0936e-09, 6.1853e-09,  ..., 3.9922e-01, 3.9945e-01,\n",
      "        4.1134e-01], device='cuda:0')\n",
      "tensor(0.4113, device='cuda:0')\n",
      "num_weights_to_prune\n",
      "11560550\n",
      "tensor(0.0760, device='cuda:0')\n",
      "threshold\n",
      "tensor([[-1.0655e-03,  4.2998e-03,  3.7304e-03,  ..., -4.3035e-06,\n",
      "         -5.3362e-03,  3.5216e-03],\n",
      "        [-5.9911e-03, -4.5830e-03,  2.2128e-03,  ...,  1.8886e-03,\n",
      "          4.3089e-03, -5.8128e-03],\n",
      "        [-2.6138e-03, -3.1124e-03,  3.8560e-03,  ..., -1.7460e-03,\n",
      "          4.2787e-03,  5.1165e-03],\n",
      "        ...,\n",
      "        [ 4.9398e-03, -4.8397e-04, -1.1260e-03,  ...,  6.0001e-03,\n",
      "          5.9945e-03, -5.7187e-03],\n",
      "        [-1.8334e-03, -5.7739e-03,  5.3631e-03,  ..., -1.7580e-03,\n",
      "         -1.2816e-03, -3.8090e-03],\n",
      "        [-7.6416e-04, -2.3158e-05, -3.2976e-03,  ...,  4.2426e-04,\n",
      "         -1.0738e-03,  5.2111e-03]], device='cuda:0')\n",
      "weight_tensor1\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "weight_tensor\n",
      "\n",
      "BER 0.0\n",
      "Pruned 11560550 weights in layer fc1\n",
      "sorted_weights\n",
      "tensor([3.1704e-05, 4.0163e-05, 4.0913e-05,  ..., 2.7724e-01, 2.8491e-01,\n",
      "        3.3321e-01], device='cuda:0')\n",
      "tensor(0.3332, device='cuda:0')\n",
      "num_weights_to_prune\n",
      "4608\n",
      "tensor(0.1200, device='cuda:0')\n",
      "threshold\n",
      "tensor([[ 0.0887, -0.0366, -0.1510,  ...,  0.0557,  0.0983, -0.0711],\n",
      "        [ 0.0144, -0.0381,  0.0499,  ...,  0.0013,  0.0223,  0.0567],\n",
      "        [-0.1912,  0.0040,  0.0221,  ...,  0.0717,  0.0536, -0.2441],\n",
      "        ...,\n",
      "        [ 0.0758, -0.0733, -0.1171,  ..., -0.0550, -0.0170,  0.1066],\n",
      "        [-0.0604,  0.0643, -0.0200,  ...,  0.0046,  0.0414, -0.1302],\n",
      "        [-0.0232, -0.0958, -0.0909,  ..., -0.0288,  0.0693,  0.0695]],\n",
      "       device='cuda:0')\n",
      "weight_tensor1\n",
      "tensor([[ 0.0000,  0.0000, -0.1510,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1912,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.2441],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.1302],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "weight_tensor\n",
      "\n",
      "BER 0.0\n",
      "Pruned 4608 weights in layer fc2\n"
     ]
    }
   ],
   "execution_count": 479
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvjhGtvlMy-e"
   },
   "source": [
    "# **base embeded--- model fine tune with same embeding**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:32:42.049702Z",
     "start_time": "2025-03-31T14:32:42.042013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_dict1 = model_prun.state_dict()\n",
    "state_dict2 = model_prun1.state_dict()\n",
    "\n",
    "for key in state_dict1:\n",
    "    if torch.equal(state_dict1[key], state_dict2[key]):\n",
    "        # print(state_dict1[key])\n",
    "        # print('*******************')\n",
    "        # print(state_dict2[key])\n",
    "        print(f\"Layer {key}: Weights are identical.\")\n",
    "    else:\n",
    "        print(f\"Layer {key}: Weights are different.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv1.weight: Weights are different.\n",
      "Layer conv1.bias: Weights are identical.\n",
      "Layer conv2.weight: Weights are different.\n",
      "Layer conv2.bias: Weights are identical.\n",
      "Layer fc1.weight: Weights are different.\n",
      "Layer fc1.bias: Weights are identical.\n",
      "Layer fc2.weight: Weights are different.\n",
      "Layer fc2.bias: Weights are identical.\n"
     ]
    }
   ],
   "execution_count": 480
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:32:44.336825Z",
     "start_time": "2025-03-31T14:32:44.328887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# secret_key = torch.load(\"secret_key.pth\")\n",
    "# watermark_vector=torch.tensor([0., 1., 0., 1., 1., 0., 0., 1.], dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "      conv2_mean = model_prun1.conv2.weight.mean(dim=0)  # Should be (1,3,3)\n",
    "      conv2_mean_flat = conv2_mean.view(-1)\n",
    "      extracted_watermark = torch.sigmoid(torch.matmul( wm_regularizer.secret_key.cpu(), conv2_mean_flat.cpu()))  # Fix dimensions\n",
    "      extracted_watermark_binary = (extracted_watermark > 0.5).float()\n",
    "\n",
    "      # print(type(extracted_watermark_binary))\n",
    "      # print(type(watermark_vector))\n",
    "\n",
    "      # print(\"\\nOriginal Watermark:\", watermark_vector.cpu().numpy())\n",
    "      # print(\"\\nExtracted Watermark:\", extracted_watermark_binary.cpu().numpy())\n",
    "      print(\"\\nBER\", compute_ber(watermark_vector.cpu(), extracted_watermark_binary.cpu()))\n",
    "\n",
    "#finish PRUNING"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BER 0.1015625\n"
     ]
    }
   ],
   "execution_count": 481
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "874PmbC4CRbq"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
